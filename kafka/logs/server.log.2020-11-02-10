[2020-11-02 11:05:43,601] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-02 11:15:43,595] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-02 11:25:43,585] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-02 11:35:43,593] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-11-02 11:41:12,150] ERROR Error while accepting connection (kafka.network.Acceptor)
java.io.IOException: Too many open files in system
	at java.base/sun.nio.ch.Net.accept(Native Method)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:276)
	at kafka.network.Acceptor.accept(SocketServer.scala:414)
	at kafka.network.Acceptor.run(SocketServer.scala:357)
	at java.base/java.lang.Thread.run(Thread.java:830)
[2020-11-02 11:42:00,938] ERROR Error while accepting connection (kafka.network.Acceptor)
java.io.IOException: Too many open files in system
	at java.base/sun.nio.ch.Net.accept(Native Method)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:276)
	at kafka.network.Acceptor.accept(SocketServer.scala:414)
	at kafka.network.Acceptor.run(SocketServer.scala:357)
	at java.base/java.lang.Thread.run(Thread.java:830)
[2020-11-02 11:42:00,993] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9092-127.0.0.1:49832-494 (kafka.network.Processor)
[2020-11-02 11:43:59,105] ERROR Error while writing to checkpoint file /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs/replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.io.FileNotFoundException: /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs/replication-offset-checkpoint.tmp (Too many open files in system)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:292)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:235)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:185)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$46.apply(ReplicaManager.scala:1387)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$46.apply(ReplicaManager.scala:1387)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1387)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1384)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1384)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:247)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:62)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
[2020-11-02 11:43:59,155] ERROR [ReplicaManager broker=0] Error while writing to highwatermark file in directory /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs/replication-offset-checkpoint
Caused by: java.io.FileNotFoundException: /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs/replication-offset-checkpoint.tmp (Too many open files in system)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(FileOutputStream.java:292)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:235)
	at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:185)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:52)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$46.apply(ReplicaManager.scala:1387)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$46.apply(ReplicaManager.scala:1387)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1387)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1384)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1384)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:247)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:62)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
[2020-11-02 11:43:59,155] INFO [ReplicaManager broker=0] Stopping serving replicas in dir /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs (kafka.server.ReplicaManager)
[2020-11-02 11:43:59,206] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions login_topic-0,events_topic-0,restSignUp_topic-0,userSignUp_topic-0,response_topic-0,eventsTopic-0 (kafka.server.ReplicaFetcherManager)
[2020-11-02 11:43:59,213] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions login_topic-0,events_topic-0,restSignUp_topic-0,userSignUp_topic-0,response_topic-0,eventsTopic-0 (kafka.server.ReplicaAlterLogDirsManager)
[2020-11-02 11:43:59,321] WARN Error processing kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec,topic=login_topic (com.yammer.metrics.reporting.JmxReporter)
javax.management.InstanceNotFoundException: kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec,topic=login_topic
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1083)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:423)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:411)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at com.yammer.metrics.reporting.JmxReporter.registerBean(JmxReporter.java:462)
	at com.yammer.metrics.reporting.JmxReporter.processMeter(JmxReporter.java:412)
	at com.yammer.metrics.reporting.JmxReporter.processMeter(JmxReporter.java:16)
	at com.yammer.metrics.core.Meter.processWith(Meter.java:131)
	at com.yammer.metrics.reporting.JmxReporter.onMetricAdded(JmxReporter.java:395)
	at com.yammer.metrics.core.MetricsRegistry.notifyMetricAdded(MetricsRegistry.java:516)
	at com.yammer.metrics.core.MetricsRegistry.getOrAdd(MetricsRegistry.java:491)
	at com.yammer.metrics.core.MetricsRegistry.newMeter(MetricsRegistry.java:240)
	at kafka.metrics.KafkaMetricsGroup$class.newMeter(KafkaMetricsGroup.scala:78)
	at kafka.server.BrokerTopicMetrics.newMeter(KafkaRequestHandler.scala:141)
	at kafka.server.BrokerTopicMetrics.<init>(KafkaRequestHandler.scala:159)
	at kafka.server.BrokerTopicStats$$anonfun$2.apply(KafkaRequestHandler.scala:195)
	at kafka.server.BrokerTopicStats$$anonfun$2.apply(KafkaRequestHandler.scala:195)
	at kafka.utils.Pool$$anonfun$getAndMaybePut$1.apply(Pool.scala:47)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:65)
	at kafka.utils.Pool.getAndMaybePut(Pool.scala:47)
	at kafka.server.BrokerTopicStats.topicStats(KafkaRequestHandler.scala:205)
	at kafka.server.ReplicaManager.kafka$server$ReplicaManager$$read$1(ReplicaManager.scala:880)
	at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:982)
	at kafka.server.ReplicaManager$$anonfun$readFromLocalLog$1.apply(ReplicaManager.scala:981)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.server.ReplicaManager.readFromLocalLog(ReplicaManager.scala:981)
	at kafka.server.ReplicaManager.readFromLog$1(ReplicaManager.scala:810)
	at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:823)
	at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:622)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:105)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Thread.java:830)
[2020-11-02 11:43:59,345] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions login_topic-0,events_topic-0,restSignUp_topic-0,userSignUp_topic-0,response_topic-0,eventsTopic-0 and stopped moving logs for partitions  because they are in the failed log directory /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs. (kafka.server.ReplicaManager)
[2020-11-02 11:43:59,355] INFO Stopping serving logs in dir /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs (kafka.log.LogManager)
[2020-11-02 11:43:59,458] ERROR Shutdown broker because all log dirs in /Users/rakshithasathyakumar/Desktop/kafka_2.11-1.1.0/F:Kafkakafka_2.11-1.1.0kafka-logs have failed (kafka.log.LogManager)
